{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95eb4702",
   "metadata": {},
   "source": [
    "# House Buying Classification: Base Models vs Bootstrap Ensemble\n",
    "\n",
    "This notebook compares three neural networks and three non-neural models on the house-buying dataset.\n",
    "\n",
    "- **Target**: `can_buy` with classes `no`, `neutral`, `yes`\n",
    "- **Methods**: NN (small/medium/deep), KNN, KMeans++, K-Medoids\n",
    "- **Ensemble**: bootstrap bagging with CV-weighted soft voting\n",
    "- **Evaluation**: accuracy, macro precision/recall/F1, balanced accuracy, log loss, ROC-AUC, confusion matrices, ROC curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Helps avoid MKL KMeans warnings on Windows\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = Path.cwd()\n",
    "if not (PROJECT_DIR / \"csv\").exists():\n",
    "    PROJECT_DIR = PROJECT_DIR.parent\n",
    "\n",
    "DATA_DIR = PROJECT_DIR / \"csv\"\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / \"house_buy_train.csv\")\n",
    "cv_df = pd.read_csv(DATA_DIR / \"house_buy_cv.csv\")\n",
    "test_df = pd.read_csv(DATA_DIR / \"house_buy_test.csv\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"buyer_income_lpa\",\n",
    "    \"house_price_lakh\",\n",
    "    \"loan_eligibility\",\n",
    "    \"credit_score\",\n",
    "    \"down_payment_percent\",\n",
    "    \"existing_emi_lpa\",\n",
    "    \"employment_years\",\n",
    "    \"dependents\",\n",
    "    \"property_location_score\",\n",
    "    \"employment_type\",\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"buyer_income_lpa\",\n",
    "    \"house_price_lakh\",\n",
    "    \"credit_score\",\n",
    "    \"down_payment_percent\",\n",
    "    \"existing_emi_lpa\",\n",
    "    \"employment_years\",\n",
    "    \"dependents\",\n",
    "    \"property_location_score\",\n",
    "]\n",
    "\n",
    "cat_cols = [\"loan_eligibility\", \"employment_type\"]\n",
    "\n",
    "label_to_int = {\"no\": 0, \"neutral\": 1, \"yes\": 2}\n",
    "int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "class_order = np.array([0, 1, 2])\n",
    "class_names = [int_to_label[i] for i in class_order]\n",
    "\n",
    "X_train_raw = train_df[feature_cols]\n",
    "y_train = train_df[\"can_buy\"].map(label_to_int).to_numpy()\n",
    "X_cv_raw = cv_df[feature_cols]\n",
    "y_cv = cv_df[\"can_buy\"].map(label_to_int).to_numpy()\n",
    "X_test_raw = test_df[feature_cols]\n",
    "y_test = test_df[\"can_buy\"].map(label_to_int).to_numpy()\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"CV shape:\", cv_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Class distribution (train):\", train_df[\"can_buy\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_cv = preprocessor.transform(X_cv_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "\n",
    "# Convert to dense arrays so every model (including custom clustering models) can consume the same inputs.\n",
    "X_train = X_train.toarray() if hasattr(X_train, \"toarray\") else np.asarray(X_train)\n",
    "X_cv = X_cv.toarray() if hasattr(X_cv, \"toarray\") else np.asarray(X_cv)\n",
    "X_test = X_test.toarray() if hasattr(X_test, \"toarray\") else np.asarray(X_test)\n",
    "\n",
    "print(\"Processed feature count:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2042d9f",
   "metadata": {},
   "source": [
    "## Custom label-aware clustering models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansLabelModel:\n",
    "    def __init__(self, n_clusters=7, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y, n_classes=3):\n",
    "        self.model = KMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            init=\"k-means++\",\n",
    "            n_init=20,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        cluster_ids = self.model.fit_predict(X)\n",
    "        self.classes_ = np.arange(n_classes)\n",
    "        self.cluster_proba_ = np.zeros((self.n_clusters, n_classes), dtype=float)\n",
    "\n",
    "        for c in range(self.n_clusters):\n",
    "            idx = np.where(cluster_ids == c)[0]\n",
    "            if len(idx) == 0:\n",
    "                self.cluster_proba_[c] = np.ones(n_classes) / n_classes\n",
    "            else:\n",
    "                counts = np.bincount(y[idx], minlength=n_classes).astype(float)\n",
    "                self.cluster_proba_[c] = (counts + 1.0) / (counts.sum() + n_classes)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        nearest_cluster = self.model.predict(X)\n",
    "        return self.cluster_proba_[nearest_cluster]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)\n",
    "\n",
    "\n",
    "class KMedoidsLabelModel:\n",
    "    def __init__(self, n_clusters=7, random_state=42, max_iter=30):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y, n_classes=3):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        k = min(self.n_clusters, n_samples)\n",
    "\n",
    "        medoid_idx = rng.choice(n_samples, size=k, replace=False)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            d2 = ((X[:, None, :] - X[medoid_idx][None, :, :]) ** 2).sum(axis=2)\n",
    "            assignments = d2.argmin(axis=1)\n",
    "\n",
    "            changed = False\n",
    "            new_medoid_idx = medoid_idx.copy()\n",
    "\n",
    "            for c in range(k):\n",
    "                pts = np.where(assignments == c)[0]\n",
    "                if len(pts) == 0:\n",
    "                    continue\n",
    "                cluster_pts = X[pts]\n",
    "                within_cluster_d2 = ((cluster_pts[:, None, :] - cluster_pts[None, :, :]) ** 2).sum(axis=2)\n",
    "                best_local_pt = pts[within_cluster_d2.sum(axis=1).argmin()]\n",
    "                if best_local_pt != medoid_idx[c]:\n",
    "                    changed = True\n",
    "                    new_medoid_idx[c] = best_local_pt\n",
    "\n",
    "            medoid_idx = new_medoid_idx\n",
    "            if not changed:\n",
    "                break\n",
    "\n",
    "        self.medoids_ = X[medoid_idx]\n",
    "        self.classes_ = np.arange(n_classes)\n",
    "\n",
    "        d2_final = ((X[:, None, :] - self.medoids_[None, :, :]) ** 2).sum(axis=2)\n",
    "        assignments = d2_final.argmin(axis=1)\n",
    "\n",
    "        self.cluster_proba_ = np.zeros((k, n_classes), dtype=float)\n",
    "        for c in range(k):\n",
    "            idx = np.where(assignments == c)[0]\n",
    "            if len(idx) == 0:\n",
    "                self.cluster_proba_[c] = np.ones(n_classes) / n_classes\n",
    "            else:\n",
    "                counts = np.bincount(y[idx], minlength=n_classes).astype(float)\n",
    "                self.cluster_proba_[c] = (counts + 1.0) / (counts.sum() + n_classes)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        d2 = ((X[:, None, :] - self.medoids_[None, :, :]) ** 2).sum(axis=2)\n",
    "        nearest_medoid = d2.argmin(axis=1)\n",
    "        return self.cluster_proba_[nearest_medoid]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)\n",
    "\n",
    "\n",
    "class SeedAveragedMLP:\n",
    "    def __init__(self, base_params, seeds):\n",
    "        self.base_params = dict(base_params)\n",
    "        self.seeds = list(seeds)\n",
    "        self.models = []\n",
    "        self.classes_ = np.array([0, 1, 2])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.models = []\n",
    "        for seed in self.seeds:\n",
    "            model = MLPClassifier(random_state=seed, **self.base_params)\n",
    "            model.fit(X, y)\n",
    "            self.models.append(model)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self.models:\n",
    "            raise RuntimeError(\"SeedAveragedMLP must be fitted before prediction.\")\n",
    "\n",
    "        n_classes = len(self.classes_)\n",
    "        avg = np.zeros((X.shape[0], n_classes), dtype=float)\n",
    "        for model in self.models:\n",
    "            proba = model.predict_proba(X)\n",
    "            aligned = np.zeros((X.shape[0], n_classes), dtype=float)\n",
    "            for col_idx, cls in enumerate(model.classes_):\n",
    "                aligned[:, int(cls)] = proba[:, col_idx]\n",
    "            avg += aligned\n",
    "        return avg / len(self.models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798a9a8",
   "metadata": {},
   "source": [
    "## Training + metric helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac740ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_models(seed):\n",
    "    return {\n",
    "        \"nn_small\": SeedAveragedMLP(\n",
    "            base_params={\n",
    "                \"hidden_layer_sizes\": (24,),\n",
    "                \"activation\": \"relu\",\n",
    "                \"solver\": \"adam\",\n",
    "                \"alpha\": 0.01,\n",
    "                \"learning_rate_init\": 0.0012,\n",
    "                \"max_iter\": 2200,\n",
    "                \"early_stopping\": True,\n",
    "                \"validation_fraction\": 0.2,\n",
    "                \"n_iter_no_change\": 25,\n",
    "            },\n",
    "            seeds=[seed + 1, seed + 11, seed + 21, seed + 31, seed + 41],\n",
    "        ),\n",
    "        \"nn_medium\": MLPClassifier(\n",
    "            hidden_layer_sizes=(44, 22),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.02,\n",
    "            learning_rate_init=0.0007,\n",
    "            max_iter=2600,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.22,\n",
    "            n_iter_no_change=20,\n",
    "            random_state=seed + 3,\n",
    "        ),\n",
    "        \"nn_deep\": MLPClassifier(\n",
    "            hidden_layer_sizes=(56, 28, 14),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.012,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=2800,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.2,\n",
    "            n_iter_no_change=25,\n",
    "            random_state=seed + 4,\n",
    "        ),\n",
    "        \"knn\": KNeighborsClassifier(n_neighbors=11, weights=\"distance\"),\n",
    "        \"kmeanspp\": KMeansLabelModel(n_clusters=9, random_state=seed + 5),\n",
    "        \"kmedoids\": KMedoidsLabelModel(n_clusters=9, random_state=seed + 6, max_iter=35),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_model(model, X, y, n_classes):\n",
    "    if isinstance(model, (KMeansLabelModel, KMedoidsLabelModel)):\n",
    "        model.fit(X, y, n_classes=n_classes)\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_proba_full(model, X, n_classes):\n",
    "    proba = model.predict_proba(X)\n",
    "\n",
    "    if proba.shape[1] == n_classes:\n",
    "        return proba\n",
    "\n",
    "    full = np.zeros((proba.shape[0], n_classes), dtype=float)\n",
    "    if hasattr(model, \"classes_\"):\n",
    "        for col_idx, cls in enumerate(model.classes_):\n",
    "            full[:, int(cls)] = proba[:, col_idx]\n",
    "    else:\n",
    "        full[:, : proba.shape[1]] = proba\n",
    "    row_sum = full.sum(axis=1, keepdims=True)\n",
    "    row_sum[row_sum == 0] = 1.0\n",
    "    return full / row_sum\n",
    "\n",
    "\n",
    "def evaluate_split(y_true, y_pred, y_proba, n_classes):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision_macro\": precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)[0],\n",
    "        \"recall_macro\": precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)[1],\n",
    "        \"f1_macro\": precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)[2],\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    labels = np.arange(n_classes)\n",
    "    y_true_bin = label_binarize(y_true, classes=labels)\n",
    "\n",
    "    try:\n",
    "        metrics[\"log_loss\"] = log_loss(y_true, y_proba, labels=labels)\n",
    "    except Exception:\n",
    "        metrics[\"log_loss\"] = np.nan\n",
    "\n",
    "    try:\n",
    "        metrics[\"roc_auc_macro_ovr\"] = roc_auc_score(y_true_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc_macro_ovr\"] = np.nan\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate_model_on_splits(model, splits, n_classes):\n",
    "    pred_store = {}\n",
    "    proba_store = {}\n",
    "    rows = []\n",
    "\n",
    "    for split_name, (X_split, y_split) in splits.items():\n",
    "        split_proba = predict_proba_full(model, X_split, n_classes=n_classes)\n",
    "        split_pred = split_proba.argmax(axis=1)\n",
    "\n",
    "        pred_store[split_name] = split_pred\n",
    "        proba_store[split_name] = split_proba\n",
    "\n",
    "        row = evaluate_split(y_split, split_pred, split_proba, n_classes=n_classes)\n",
    "        row[\"split\"] = split_name\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows, pred_store, proba_store\n",
    "\n",
    "\n",
    "def select_ensemble_families(base_metrics_df, top_k=2):\n",
    "    cv_rank = (\n",
    "        base_metrics_df[base_metrics_df[\"split\"] == \"cv\"]\n",
    "        .sort_values(\"f1_macro\", ascending=False)\n",
    "    )\n",
    "    return cv_rank.head(top_k)[\"model\"].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51840edb",
   "metadata": {},
   "source": [
    "## Train individual models (3 NNs + KNN + KMeans++ + K-Medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44536a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    \"train\": (X_train, y_train),\n",
    "    \"cv\": (X_cv, y_cv),\n",
    "    \"test\": (X_test, y_test),\n",
    "}\n",
    "\n",
    "n_classes = len(class_order)\n",
    "base_models = build_base_models(seed=42)\n",
    "\n",
    "base_metrics_rows = []\n",
    "base_predictions = {name: {} for name in base_models}\n",
    "base_probabilities = {name: {} for name in base_models}\n",
    "\n",
    "for model_name, model in base_models.items():\n",
    "    fit_model(model, X_train, y_train, n_classes=n_classes)\n",
    "    rows, pred_store, proba_store = evaluate_model_on_splits(model, splits, n_classes=n_classes)\n",
    "\n",
    "    for row in rows:\n",
    "        row[\"model\"] = model_name\n",
    "        base_metrics_rows.append(row)\n",
    "\n",
    "    base_predictions[model_name] = pred_store\n",
    "    base_probabilities[model_name] = proba_store\n",
    "\n",
    "base_metrics_df = pd.DataFrame(base_metrics_rows)\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"precision_macro\",\n",
    "    \"recall_macro\",\n",
    "    \"f1_macro\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"log_loss\",\n",
    "    \"roc_auc_macro_ovr\",\n",
    "]\n",
    "\n",
    "for split_name in [\"train\", \"cv\", \"test\"]:\n",
    "    print(f\"\\n=== BASE MODELS: {split_name.upper()} ===\")\n",
    "    display(\n",
    "        base_metrics_df[base_metrics_df[\"split\"] == split_name]\n",
    "        .set_index(\"model\")[metric_cols]\n",
    "        .sort_values(\"f1_macro\", ascending=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700472b5",
   "metadata": {},
   "source": [
    "## Bootstrap bagging ensemble (adaptive top-family selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 14\n",
    "ensemble_top_k = 2\n",
    "ensemble_cv_threshold = 0.78\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "ensemble_proba_sum = {\n",
    "    \"train\": np.zeros((len(y_train), n_classes), dtype=float),\n",
    "    \"cv\": np.zeros((len(y_cv), n_classes), dtype=float),\n",
    "    \"test\": np.zeros((len(y_test), n_classes), dtype=float),\n",
    "}\n",
    "\n",
    "weight_total = 0.0\n",
    "weight_records = []\n",
    "kept_learners = 0\n",
    "\n",
    "model_names = list(build_base_models(seed=42).keys())\n",
    "selected_families = select_ensemble_families(base_metrics_df, top_k=ensemble_top_k)\n",
    "\n",
    "for b in range(n_bootstrap):\n",
    "    sample_idx = rng.integers(0, len(y_train), size=len(y_train))\n",
    "    X_boot = X_train[sample_idx]\n",
    "    y_boot = y_train[sample_idx]\n",
    "\n",
    "    models_b = build_base_models(seed=1000 + b * 17)\n",
    "\n",
    "    for model_name in selected_families:\n",
    "        model = models_b[model_name]\n",
    "        fit_model(model, X_boot, y_boot, n_classes=n_classes)\n",
    "\n",
    "        cv_proba = predict_proba_full(model, X_cv, n_classes=n_classes)\n",
    "        cv_pred = cv_proba.argmax(axis=1)\n",
    "        cv_f1 = f1_score(y_cv, cv_pred, average=\"macro\")\n",
    "\n",
    "        if cv_f1 < ensemble_cv_threshold:\n",
    "            continue\n",
    "\n",
    "        # Square weighting rewards stronger CV learners and downweights borderline ones.\n",
    "        weight = max(float(cv_f1) ** 2, 0.02)\n",
    "        weight_total += weight\n",
    "        kept_learners += 1\n",
    "\n",
    "        for split_name, (X_split, _) in splits.items():\n",
    "            split_proba = predict_proba_full(model, X_split, n_classes=n_classes)\n",
    "            ensemble_proba_sum[split_name] += weight * split_proba\n",
    "\n",
    "        weight_records.append(\n",
    "            {\n",
    "                \"bootstrap_iter\": b,\n",
    "                \"model\": model_name,\n",
    "                \"cv_f1\": cv_f1,\n",
    "                \"vote_weight\": weight,\n",
    "            }\n",
    "        )\n",
    "\n",
    "if kept_learners == 0:\n",
    "    raise RuntimeError(\"No ensemble learners passed the CV threshold. Lower `ensemble_cv_threshold`.\")\n",
    "\n",
    "ensemble_probabilities = {k: v / weight_total for k, v in ensemble_proba_sum.items()}\n",
    "ensemble_predictions = {k: v.argmax(axis=1) for k, v in ensemble_probabilities.items()}\n",
    "\n",
    "ensemble_rows = []\n",
    "for split_name, (_, y_true) in splits.items():\n",
    "    row = evaluate_split(\n",
    "        y_true,\n",
    "        ensemble_predictions[split_name],\n",
    "        ensemble_probabilities[split_name],\n",
    "        n_classes=n_classes,\n",
    "    )\n",
    "    row[\"model\"] = \"bootstrap_ensemble\"\n",
    "    row[\"split\"] = split_name\n",
    "    ensemble_rows.append(row)\n",
    "\n",
    "ensemble_metrics_df = pd.DataFrame(ensemble_rows)\n",
    "\n",
    "print(f\"Bootstrap iterations: {n_bootstrap}\")\n",
    "print(f\"Selected model families for ensemble: {selected_families}\")\n",
    "print(f\"CV threshold: {ensemble_cv_threshold}\")\n",
    "print(f\"Kept learners: {kept_learners}\")\n",
    "display(ensemble_metrics_df.set_index(\"model\")[[\"split\"] + metric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567270f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df = pd.concat([base_metrics_df, ensemble_metrics_df], ignore_index=True)\n",
    "\n",
    "for split_name in [\"train\", \"cv\", \"test\"]:\n",
    "    print(f\"\\n=== ALL MODELS: {split_name.upper()} ===\")\n",
    "    display(\n",
    "        all_metrics_df[all_metrics_df[\"split\"] == split_name]\n",
    "        .set_index(\"model\")[metric_cols]\n",
    "        .sort_values(\"f1_macro\", ascending=False)\n",
    "    )\n",
    "\n",
    "best_single_by_cv = (\n",
    "    base_metrics_df[base_metrics_df[\"split\"] == \"cv\"]\n",
    "    .sort_values(\"f1_macro\", ascending=False)\n",
    "    .iloc[0][\"model\"]\n",
    ")\n",
    "\n",
    "print(\"Best single model by CV macro F1:\", best_single_by_cv)\n",
    "print(\"\\nTest report (best single):\")\n",
    "print(classification_report(y_test, base_predictions[best_single_by_cv][\"test\"], target_names=class_names))\n",
    "print(\"Test report (bootstrap ensemble):\")\n",
    "print(classification_report(y_test, ensemble_predictions[\"test\"], target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113b09b",
   "metadata": {},
   "source": [
    "## Visual comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order = model_names + [\"bootstrap_ensemble\"]\n",
    "\n",
    "plot_df = all_metrics_df.copy()\n",
    "plot_df[\"model\"] = pd.Categorical(plot_df[\"model\"], categories=plot_order, ordered=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    data=plot_df,\n",
    "    x=\"model\",\n",
    "    y=\"accuracy\",\n",
    "    hue=\"split\",\n",
    "    ax=axes[0],\n",
    "    order=plot_order,\n",
    ")\n",
    "axes[0].set_title(\"Accuracy by model and split\")\n",
    "axes[0].set_ylim(0, 1.05)\n",
    "axes[0].tick_params(axis=\"x\", rotation=35)\n",
    "\n",
    "sns.barplot(\n",
    "    data=plot_df,\n",
    "    x=\"model\",\n",
    "    y=\"f1_macro\",\n",
    "    hue=\"split\",\n",
    "    ax=axes[1],\n",
    "    order=plot_order,\n",
    ")\n",
    "axes[1].set_title(\"Macro F1 by model and split\")\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].tick_params(axis=\"x\", rotation=35)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cm_single = confusion_matrix(y_test, base_predictions[best_single_by_cv][\"test\"], labels=class_order)\n",
    "cm_ens = confusion_matrix(y_test, ensemble_predictions[\"test\"], labels=class_order)\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_single,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(f\"Best single ({best_single_by_cv}) - test\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_ens,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Greens\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Bootstrap ensemble - test\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae12829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-rest ROC curves for the bootstrap ensemble on test split\n",
    "y_test_bin = label_binarize(y_test, classes=class_order)\n",
    "proba_ens_test = ensemble_probabilities[\"test\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], proba_ens_test[:, i])\n",
    "    auc_i = roc_auc_score(y_test_bin[:, i], proba_ens_test[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC={auc_i:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", alpha=0.7)\n",
    "plt.title(\"Bootstrap ensemble ROC curves (test, OvR)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9430c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = pd.DataFrame(weight_records)\n",
    "mean_weight = (\n",
    "    weight_df.groupby(\"model\", as_index=False)[\"vote_weight\"]\n",
    "    .mean()\n",
    "    .sort_values(\"vote_weight\", ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=mean_weight, x=\"model\", y=\"vote_weight\", palette=\"viridis\")\n",
    "plt.title(\"Average ensemble vote weight by model type\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Average vote weight (from CV macro F1)\")\n",
    "plt.xticks(rotation=25)\n",
    "plt.tight_layout()\n",
    "\n",
    "mean_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d4d24",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- `nn_small` is now a seed-averaged neural model (5 seeds) to reduce variance.\n",
    "- Scaled dataset (train/cv/test = 3000/400/300) gives more stable CV and test behavior.\n",
    "- Ensemble uses adaptive top-family selection from CV (`top_k=2`) with a CV quality gate and squared weighting.\n",
    "- KNN and clustering models are still tracked in single-model comparisons for diversity diagnostics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}